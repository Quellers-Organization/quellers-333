

// Index settings

[discrete]
[[elasticsearch-intro-index-settings]]
==== Index settings

<<index-modules-settings,Index settings>> are important for managing and optimizing your Elasticsearch cluster.
Because Elasticsearch is distributed, indices are divided into one or more <<scalability,shards>> for performance, scalability, and resilience.
Use settings to control various index parameters, such as the number of shards, replicas, and the lifecycle of data in the index.

Index settings are critical for production use cases.
Settings are much easier to define at index creation time than to change later.


Ingestion

{es} indexes your source documents with optimized structures for different data types.
For example, text is stored in an inverted index, making it fully searchable in near real time.
Numeric and geo fields are stored in BKD trees.
Dense vectors are stored in HNSW graphs which enables {es} vector database capabilities.
Per-field data structures help {es} <<near-real-time,retrieve search results fast>>.


[discrete]
[[elasticsearch-intro-text-analysis]]
==== Text analysis

<<analysis-overview,Text analysis>> is the process of converting unstructured text into a structured format, optimized for full-text search.
Full-text search returns relevant results rather than just exact matches.
Analysis happens in a chain of steps:

* *Tokenization*. A <<analysis-tokenizers,tokenizer>> receives a stream of characters, breaks it up into individual tokens (usually individual words), and outputs a stream of tokens. 
* *Normalization*. <<analysis-tokenfilters,Token filters>> can add, delete, or modify tokens in the stream.
For example, a lowercase filter converts all tokens to lowercase.
An analyzer can have zero or more token filters, which are applied in order.

{es} has a number of built-in analyzers that you can use out of the box.
For advanced use cases, you can create <<analysis-custom-analyzer,custom analyzers>>.

The analysis chain is applied at both index time and search (or query) time.
This ensures the query string and the indexed data are optimized for matching.

[discrete]
[[elasticsearch-intro-vector-search]]
==== Vector search

Lexical text analysis transforms text into a format optimized for term matching.
Techniques like tokenization and normalization are powerful tools for finding different forms of words,
but they still suffer from the https://en.wikipedia.org/wiki/Vocabulary_mismatch[vocabulary mismatch problem].
For example, a lexical search for "dog" won't match "puppy" or "canine", even though they are semantically similar.

Modern search users expect to find relevant results based on semantic relationships.
Embedding models are machine learning models that transform text into a format optimized for matching semantically similar content.
Source documents are transformed into vectors (or matrices) of floating-point numbers.
Semantically similar data points sit in the same regions of the vector space, while dissimilar data points are farther apart.
Distance calculations can be used to find similar vectors.
This is known as vector search.

In practice, text analysis for full-text search and embeddings for vector search achieve the same outcome.
They both transform unstructured data into a structured format that can be efficiently searched and retrieved.
Like text analysis, vector search requires index time and query time processing.
Queries must be transformed using the same embedding model to ensure that the search results are relevant.

Both have their pros and cons, but the combination of lexical and vector search provides superior search relevance.
// DO LINKS

[discrete]
[[elasticsearch-intro-hybrid-search]]
==== Hybrid search

Hybrid search is the combination of traditional full-text search and vector search.
The `semantic` query can be used as a part of a hybrid search system, combined with traditional lexical queries.
Use the reciprocal rank fusion (RRF) algorithm to combine results from different retrieval techniques.
Refer to <<rrf-using-multiple-standard-retrievers,the RRF documentation>> for more information.