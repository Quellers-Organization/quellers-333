[role="xpack"]
[[semantic-text]]
=== Semantic text field type
++++
<titleabbrev>Semantic text</titleabbrev>
++++

experimental[]

The `semantic_text` field type automatically generates embeddings for text
content using an inference service. 

The `semantic_text` field type specifies an `inference_id` of the NLP model that
will be used to generate the embeddings. This field type and the 
<<query-dsl-semantic-query,`semantic` query>> type make it simpler to perform
semantic search on your data.

Using `semantic_text`, you won't need to specify how to generate embeddings for
your data, or how to index it. The inference service specified automatically
determines the embedding generation, indexing, and query to use.

[source,console]
------------------------------------------------------------
PUT my-index-000001
{
    "mappings": {
        "properties": {
            "inference_field": { <1>
                "type": "semantic_text",<2>
                "inference_id": "my-elser-model" <3>
	     }
        }
    }
}
------------------------------------------------------------
// TEST[skip:TBD]
<1> The field that will contain the tokens generated by an NLP model.
<2> The filed type is `semantic_text`.
<3> The `inference_id` of the inference endpoint to use to generate the
embeddings.


[discrete]
[[semantic-text-params]]
==== Parameters for `semantic_text` fields

`inference_id`::
(Required, string)  
You must provide an `inference_id` of an inference endpoint when creating the
`semantic_text` field type. This inference endpoint will be used to generate the
embeddings for the field tokens and their vector representation based on the
documents ingested into the index. Use the <<put-inference-api>> to create the
endpoint.


[discrete]
[[infer-service-validation]]
==== {infer-cap} service validation

The `inference_id` will not be validated when the mapping is created, but when
documents are ingested into the index. When the first document is indexed, the
`inference_id` will be used to generate underlying indexing structures for the
field.


[discrete]
[[auto-text-chunking]]
==== Automatic text chunking

{infer-cap} services have a limit on the amount of text they can process. To
allow for large amounts of text to be used in semantic search, `semantic_text`
automatically generates smaller passages if needed called chunks.

Each chunk will include the text subpassage and its corresponding embedding
generated from it. When querying, the individual passages will be automatically
searched for each document, and the score combined to obtain relevant results.


[discrete]
[[semantic-text-structure]]
==== `semantic_text` structure

Once ingested, a `semantic_text` field will have the following structure:

[source,console-result]
------------------------------------------------------------
"inference_field": {
  "text": "these are not the droids you're looking for", <1>
  "inference": {
    "inference_id": "my-elser-model", <2>
    "model_settings": { <3>
      "task_type": "sparse_embedding"
    },
    "chunks": [ <4>
      {
        "text": "these are not the droids you're looking for",
        "embeddings": {
		(...)
        }
      }
    ]
  }
}
------------------------------------------------------------
// TEST[skip:TBD]
<1> The field will become an object structure to accommodate both the original
text and the inference results.
<2> The `inference_id` used to generate the embeddings.
<3> Model settings, including the task type and dimensions/similarity if
applicable.
<4> Inference results will be grouped in chunks, each with its corresponding
text and embeddings.

Refer to <<semantic-search-semantic-text,this tutorial>> to learn more about
semantic search using `semantic_text` and `semantic_query`.
